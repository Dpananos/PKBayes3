---
title: "Paper 3"
author:
  - "A. Demetri Pananos"
  - "Daniel J. Lizotte"
output: pdf_document
date: "`r format(Sys.time(), '%B %d, %Y')`"
bibliography: references.bib  
---


```{r global-options, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(
  echo = F,
  message = F,
  warning = F,
  fig.height = 4,
  fig.align = 'center',
  dpi = 400,
  cache = F
)
```

```{r libraries}
library(tidyverse)
library(rstanarm)
library(tidybayes)
library(cmdstanr)
library(duckdb)
library(DBI)
source('R/utils.R')

theme_set(theme_light())
cmdstanr::register_knitr_engine(override = F)
```


# Introduction

One goal of personalized medicine is optimized dosing of drugs for individuals [-@morse2015personalized].  When considering optimal doses, a thorough understanding pharmacokinetic (what the body does to the drug) and/or pharmacodynamic (what the drug does to the body) effects are crucial.  To this end, models describing the mediation of pharmacokinetic effects via clinical, genetic, and lifestyle factors have an important role in deciding which patients should get what dose.

For the oral anticoagulant apixaban, pharmacokinetic models have been previously published [-@cirincione2018population, -@ueshima2018population] in collaboration with drug manufacturers using data from clinical trials.  These studies identified age, sex, body weight, renal function,  patient race, and CYP3A4 inhibitors as modulators of apixaban pharmacokientics [-@cirincione2018population], though according to authors the effects of some of these variables were not large enough to require clinical dose adjustment. However, even after adjusting for the aforementioned factors, concentrations of apixaban in real life applications have been observed to be larger than what was reported in clinical trials [-@sukumar2019apixaban], raising questions as to the optimal dosing of apixaban for patients outside these trials. Additionally, recent research has indicated appropriateness of dose adjustment criteria are unclear [-@vu2021critical], citing there is no reduction in safety in patients above 75 years of age, below 60kg of body weight, and egfr lower than50 mL/min.  

The uncertainty regarding dosing criteria and additional variability in concentrations in day to day use suggest that, while previously published models may be internally valid, these models may not be representative of all populations in which apixaban is to be applied.  That is to say, the models may lack external validity.  Creating similar pharmacokinetic models for use in a specific population may have two goals:  to adjust dosing criteria to be specific for a population, and/or to explore how additional variables not included in the aforementioned studies effect particular parts of the pharmacokinetics of apixaban.  This study seeks to demonstrate how investigators can fit similar models to their pharmacokinetic data with the aim of accomplishing these goals.

We leverage a Bayesian approach to building pharmacokinetic models so that we may incorporate prior information from previous studies. Additionally, we describe how investigators can use *all* relevant data available to them to fit these models and make inferences.  Finally, we show how sparsity inducing priors can be applied to new variables in order to explore how those variables may effect apixaban pharmacokinetics, encouraging small effects but allowing for large effects to be detected.  Finally, we use an open source Bayesian language to develop our models, making our code freely available.  Previous models are constructed in a proprietary software toolset, which can come at a high cost. Creation of these models in a free tool removes a barrier to research, making these methods more widely available.




* Part of the goal of personalized medicine is to optimize drug therapies while controlling the risk of adverse events [-@morse2015personalized]
* A utpoic goal may be to have centralized personalization; one resource we can look to and ask how to optimize a therapy for this patient, regardless of where that patient comes from.
* Though laudable, the reality is that drug concentrations can be more variable than what is observed in clinical trials [-@sukumar2019apixaban].  This excess variability makes centralized personalization difficult.
*  Though existing models PK for some drugs may suffer from a lack of external validity, the information contained therein is still a good starting point.  In particular, if a Bayesian approach is used, then model effects form previous studies can be passed as prior information.

* Additionally, Bayesian techniques allow for more expressive and thoughtful modelling, allowing data from well controlled clinical studies as well as real life data to be used in the modelling procedure.
* The result is (maybe) a model which uses existing information as a starting point but is *personalized* to the population you care about, using all data available to you.
* We demonstrate this workflow using apixaban.  Apixaban's pharmacodynamic effect is closely correlated to blood plasma levels [-@upreti2013effect,-@frost2013safety,-@frost2013apixaban, so work with concentrations directly.
* Additionally, if we have additional covariates we are interested in exploring, we can incorporate these into our model to estimate additional effects in our population.  Relying on previously published models for dosing recomendations may leave infomration on the table.




* Data probably not available, what do you do?
* Priors from papers
* Combine all the data you can get in a smart way
* Can explore *and* personalize with this model
* Here are some things you can do
* In conclusion, its insane that this data is private.  Don't get soapboaxy, but if we had them we could incorporate into the model.

# Background

## Apixaban

Our study uses clinical and experimental plasma concentrations from patients who were prescribed apixaban. Apixaban is a direct acting oral anti-coagulant often prescribed for prevention of stroke and systemic embolism in patients with atrial fibrillation (AF) [-@BMSmonograph; -@byon2019apixaban].  Studies as recent as 2019 have reported excess variability in observed apixaban plasma concentrations in patients with AF [-@sukumar2019apixaban]. Since apixaban plasma concentrations correlate closely with anti-coagulation[-@upreti2013effect,-@frost2013safety,-@frost2013apixaban], excess variability in these concentrations may mean increased risk of bleeding. These findings have raised questions towards the optimal dosing of apixaban in older adults with AF encountered outside of clinical trials.

Additional research into determining factors which explain this excess variability beyond known clinical factors [-@gulilat2020drug] has consequently begun.

## Methods


## Bayesian Model

Our model specifies a population level effect of covariates (age, sex, weight (kg), serum creatinine $\mu \mbox{mol}$) on patient clearance, time to max concentration, and the ratio between absorption and elimination rates (a unitless parameter we refer to as $\alpha$). These effects are shared between the two populations, allowing information from one dataset to partially inform model fit on the other.  We also include a population level effect of concomitant amidarone on bioavailability of apixaban.  

We fit our model using Stan [-@gelman2015stan], an open source probabilistic programming language with interfaces to Python, R, Stata, Matlab, and more.  Fittting two datasets jointly is formally equivalent to fitting one dataset first and passing the posterior as a prior for a model for the other dataset.  However, such an approach requires summarization of the posterior, which may result in loss of information (such as covariance between draws, unless explicitly modeled).  The recommended approach is then to fit datasets jointly, as done in [-@fallingBetancourt].

### Experimental Data (Dataset 1) Model

Since patients are observed multiple times in these data, this offers the opportunity to estimate random effects for Clearence $Cl$, time to mac concentration $t_{\max}$, ratio between elimination and absorption rates $\alpha = k_e/k_a$.

Let $X$ be a matrix of mean centered and standardized covariates for dataset 1.  For patient $j$, we model the pharmacokientic parameters as

$$ \log(Cl_{j}) = \mu_{Cl} + X\beta_{Cl} + z_{Cl, j} \sigma_{Cl}  $$
$$ \log(t_{\max,j}) = \mu_{t_{\max}} + X\beta_{t_{max}} + z_{t_{\max, j}}\sigma_{t_{\max}}  $$

$$ \operatorname{logit}(\alpha_{j})  =  \mu_{\alpha} + X\beta_{\alpha} + z_{\alpha, j}\sigma_{\alpha}  $$

Here, the $\mu$ are the population level means for the indicated pharmacokinetic parameters, the $\beta$ are the regression coefficients, the $z$ are standard normal random variables to account for random effects, and the $\sigma$ are the standard deviations of the population distribution for the indicated pharmacokinetic parameters. Additionally, we model the population mean for the bioavailability as $F = 1/(1 + e^{\mu_F}$, with a prior on $\mu_F$.  Both the $\mu$ and the $\beta$ are shared between datasets.

For dataset 1, we also model a delay between ingestion and absorption of apixaban.  The delay is modeled as 

$$ \delta_j = 0.5 \times b  $$

Where $b$ is a beta distributed random variable with parameters learned from the data.  The factor of 0.5 is used to ensure that at $t=0.5$ hours after ingestion, the predicted to be non-zero.

We use a one compartment pharmacokinetic model with first order elimination as our conditional mean

$$  C_{j}(t)= \begin{cases}\frac{F \cdot D}{C l_j} \frac{k_{e, j} \cdot k_{a, j}}{k_{e, j}-k_{a, j}}\left(e^{-k_{a, j}(t-\delta_j)}-e^{-k_{e, j}(t-\delta_j)}\right) & \delta_j \leq t \\ 0 & \text { else }\end{cases} \>. $$
Here, all parameters are estimated from data, and we have used the facts that

$$ t_{\max }=\frac{\ln \left(k_{a}\right)-\ln \left(k_{e}\right)}{k_{a}-k_{e}} $$
$$ \alpha = \dfrac{k_e}{k_a} $$

in order to solve for $k_e$ and $k_a$ for use in our PK model.  Finally, we specify a lognormal likelihood for dataset 1

$$ y_j \sim \mbox{Lognormal}(C_j(t), \sigma_1) \>. $$

For information of prior distributions, see our supplement.

### Observational (Dataset 2) Model

Much of the structure from the previous model is translated to dataset 2.  However, there are a few differences.

Because patients in this dataset are not measured multiple times we do not estimate random effects or a time delay.  Hence, we model

$$ \log(Cl) = \mu_{Cl} + X\beta_{Cl} $$

$$ \log(t_{\max}) = \mu_{t_{\max}} + X\beta_{t_{\max}} $$

$$\operatorname{logit}(a) = \mu_\alpha + X\beta_{\alpha} $$

Where the $mu$ and the $\beta$ are shared between datasets.  Additionally, we model the bioavailbility as 

$$ \operatorname{logit}(F) = \mu_F   + \beta_{amio} \mbox{amiodarone}$$

as dataset 2 has information regarding concomitant amiodarone.  

Finally, data from dataset 2 comes from patients who have been taking apixaban twice daily.  Hence, their initial plasma concentration on ingestion is not 0, but can be modeled using the pharmacokientics none the less.  Assuming the patients have been taking apixaban twice a day, 12 hours apart, for the last 5 days, the initial concentration can be shown to be

$$ C_0 = \sum_{j=1}^{10} C(12j) \>. $$

Here, $C(t)$ is the pharmacokintic profile with estimated coefficients for that patient.  See our supplement for a proof of this proposition.

Our pharmacokientic profile is again provided by a one compartment first order elimination 

$$  C(t)= c_0 + \frac{F \cdot D}{C l} \frac{k_{e} \cdot k_{a}}{k_{e}-k_{a}}\left(e^{-k_{a}(t)}-e^{-k_{e}(t)}\right)  $$
and we assume a lognormal likelihood

$$ y_j \sim \mbox{Lognormal}(C(t), \sigma_2) \>. $$
Note the likelihood for dataset 2 has a different observational noise component ($\sigma_2$) as compared to dataset 1 ($\sigma_1$).  This is because random effects can not be estimated from dataset 2, hence the residual variance is part observational noise and part between subject variability conditional on the subject covariates.

# Results

```{r load-in-data}
con = dbConnect(duckdb(),'data/database/apixaban_data.duckdb')

ute_data = tbl(con, 'ute_cleaned_data') %>% 
           collect() %>% 
           mutate(
             dataset = "Ute's Data",
             i = seq_along(subjectids)
           ) 

rommel_data = tbl(con, 'rommel_cleaned_data') %>% 
              collect() %>% 
              mutate(
                subjectids = as.character(subjectids),
                dataset = "Rommel's Data"
                )

dbDisconnect(con, shutdown=T)


```

```{r load-in-model}
fit = readRDS('model_009.RDS')
```


```{r plot-model-predictions}

# Check for data from one of those data.
# Public apixaban data?
rommel_fit = fit %>% 
  spread_draws(r_C[i]) %>% 
  mutate(r_C = 1000*r_C) %>% 
  mean_qi() %>% 
  bind_cols(rommel_data) %>% 
  rename(predictions=r_C)


ute_fit = fit %>% 
  spread_draws(u_C[i]) %>% 
  mutate(u_C = 1000*u_C) %>% 
  mean_qi() %>% 
  bind_cols(ute_data) %>% 
  rename(predictions=u_C)

rommel_fit %>% 
  bind_rows(ute_fit) %>% 
  ggplot(aes(log(yobs_ng_ml), log(predictions), ymin = log(.lower), ymax = log(.upper)))+
  geom_pointrange(size=0.1)+
  geom_abline(color='dark grey')+
  facet_wrap(~dataset, scale='free')+
  theme(aspect.ratio = 0.62)+
  labs(x='Log Concentration', y='Log Prediction')

ggsave('prediction_v_actual.png', path='figures')
knitr::plot_crop('figures/prediction_v_actual.png')

MLmetrics::R2_Score(
  
  log(ute_fit$predictions),
  log(ute_fit$yobs_ng_ml)
)

model = lm(log(yobs_ng_ml) ~ hrs_post_dose + weight_kg + age + sex + dose_mg_twice_daily + creatinine_micromol_l + diltiazem_mg_day + amiodarone_mg_day, data = ute_data)

a = predict(model)
b = log(ute_fit$predictions)
c = log(ute_fit$yobs_ng_ml) 

MLmetrics::R2_Score(a, c)
MLmetrics::R2_Score(b, c)
plot(a, b)
abline(0, 1)
```

```{r}

fit %>% 
  spread_draws(mu_F, b_F_amio) %>% 
  crossing(amio_dose = seq(0, 1.0, 0.25)) %>% 
  mutate(effective_dose = 5.0*plogis(mu_F + amio_dose*b_F_amio),
        dose_label = factor(str_c(400*amio_dose, ' mg/day'))) %>% 
  
  select(dose_label, effective_dose) %>% 
  ggplot(aes(effective_dose, dose_label))+
  stat_gradientinterval(fill='red')+
  labs(y='Amiodarone', x='Effective dose of apixaban mg')
```


```{r}

conc = function(time, d, f,cl, ke, ka, c0){
  d*f*ke*ka/(cl*(ke-ka)) * (exp(-ka*time) - exp(-ke*time)) + c0
}

preds = fit %>% 
  spread_draws(u_Cl[i], u_ke[i], u_ka[i], u_F[i], u_C0[i], ndraws = 1000) %>% 
  left_join(ute_data) %>% 
  crossing(time = seq(0, 12, 0.5)) %>% 
  mutate(
    y = conc(time, dose_mg_twice_daily, u_F, u_Cl, u_ke, u_ka, u_C0)
  ) %>% 
  ungroup %>% 
  group_by(i, time) %>% 
  mean_qi(y)


file_name = 'figures/conc_by_sex.png'
preds %>% 
  left_join(ute_data) %>% 
  ggplot(aes(time, 1000*y, color=sex, group = i))+
  geom_line(alpha = 0.5, show.legend = F)+
  facet_grid(~sex)+
  theme(aspect.ratio = 0.62)+
  labs(x='Hours Post Dose', y='Concentration (ng/ml)')

ggsave(file_name)
knitr::plot_crop(file_name)
```


```{r}

x = tibble(
  .var = c('age','amio','creatinine','is','weight'),
  variable = c('Age','Amiodarone','Creatinine','Is Male', 'Weight')
)


# Clearance

mus = fit %>% 
      spread_draws(mu_cl) %>% 
      rename(mu = mu_cl)

cl = fit %>% 
  spread_draws(`b_cl.*`, regex=T) %>% 
  mutate(b_cl_Reference=0) %>% 
  rename(b_cl_male = b_cl_is_male) %>% 
  pivot_longer(cols=starts_with('b_cl'), names_to='.variable') %>% 
  left_join(mus) 

#elimination

mus = fit %>% 
      spread_draws(mu_ke) %>% 
      rename(mu = mu_ke)

ke = fit %>% 
  spread_draws(`b_ke.*`, regex=T) %>% 
  mutate(b_ke_Reference=0) %>% 
  rename(b_ke_male = b_ke_is_male) %>% 
  pivot_longer(cols=starts_with('b_ke'), names_to='.variable') %>% 
  left_join(mus) 


# Bio availability
mus = fit %>% 
      spread_draws(mu_F) %>% 
      rename(mu = mu_F)

Fs = fit %>% 
  spread_draws(`b_F.*`, regex=T) %>% 
  mutate(b_F_Reference=0) %>% 
  pivot_longer(cols=starts_with('b_F'), names_to='.variable') %>% 
  left_join(mus) 




file_name = 'figures/effects.png'

bind_rows(cl, ke, Fs) %>% 
  separate(.variable, into = c('b','pk','covar')) %>%
  mutate(covar = if_else(covar=='amio', 'amio (400 mg/day)', covar)) %>% 
  mutate(
    estimate = case_when(pk=='F'~plogis(mu + value), T~ exp(value + mu)),
    covar = str_to_sentence(covar)
  ) %>% 
    mutate(covar = factor(covar),
         covar = relevel(covar, ref='Reference')
         ) %>% 
  ggplot(aes(estimate, fct_rev(covar)))+
  stat_pointinterval()+
  facet_wrap(~pk, scale = 'free_x')+
  theme(aspect.ratio = 1)+
  labs(y='', x='Estimate')
  
ggsave(file_name)
knitr::plot_crop(file_name)

    
```






# References