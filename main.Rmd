---
title: "Paper 3"
author:
  - "A. Demetri Pananos"
  - "Daniel J. Lizotte"
output: pdf_document
date: "`r format(Sys.time(), '%B %d, %Y')`"
bibliography: references.bib  
---


```{r global-options, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(
  echo = F,
  message = F,
  warning = F,
  fig.height = 4,
  fig.align = 'center',
  dpi = 400,
  cache = F
)
```

```{r libraries}
library(tidyverse)
library(rstanarm)
library(tidybayes)
library(cmdstanr)
library(duckdb)
library(DBI)
source('R/utils.R')

theme_set(theme_light())
cmdstanr::register_knitr_engine(override = F)
```


# Introduction

* Unified model for researchi and clincial use.
* "If you're thinking about your clinic as a learning system, practice to inform practice"
* broader goal is make modelling available + right way to do discovery
* "What is the best modelling job you can do given your data"
* Mechanistic knowledge + bring in other data: 2 bring data
* Expand the data you have
* Simulation study.  simple study to see what kinds of effects of
* Interested in one particular PK because some of these drugs are effecting clearance.

One goal of personalized medicine is optimized dosing of drugs for individuals [-@morse2015personalized].  When considering optimal doses, a thorough understanding pharmacokinetic (what the body does to the drug) and/or pharmacodynamic (what the drug does to the body) effects are crucial.  To this end, models describing the mediation of pharmacokinetic/pharmacodynamic effects via clinical, genetic, and lifestyle factors have an important role in deciding which patients should get what dose.  These models are sometimes published by research teams collaborating with drug manufacturers using data from clinical trials.

Indepenedent investigators can find themselves in a situation in which data collection from a particular population of interest is achievable. If the data come from practice (e.g. a personalized medical clinic), there may be questions about how new variables not previously studied in clinical trials effect the pharmacokientics/pharamcodynamics of a particular drug.  Running large studies in order to examine the effects of these new variables, or discover effects of other variables, may be out of reach due to a variety of constraints.  Consequently, investigators must think about how best to model the pharmacokinetics, for use in decision making *and* exploration, using data available to them.

Apixaban is one example of such a scenario.  Pharmacokinetic models have been previously published [-@cirincione2018population, -@ueshima2018population] in collaboration with the drug's manufactur using data from clinical trials.  These studies identified age, sex, body weight, renal function,  patient race, and CYP3A4 inhibitors as modulators of apixaban pharmacokinetics [-@cirincione2018population], though according to authors the effects of some of these variables were not large enough to require clinical dose adjustment. However, even after adjusting for the aforementioned factors, concentrations of apixaban in real life applications have been observed to be larger than what was reported in clinical trials [-@sukumar2019apixaban], raising questions as to the optimal dosing of apixaban for patients outside these trials. Additionally, recent research has indicated appropriateness of dose adjustment criteria are unclear [-@vu2021critical], citing there is no reduction in safety in patients above 75 years of age, below 60kg of body weight, and egfr lower than50 mL/min.  

The uncertainty regarding dosing criteria and additional variability in concentrations in day to day use suggest that, while previously published models may be internally valid, these models may not be representative of all populations in which apixaban is to be applied.  That is to say, the models may lack a degree of external validity, thus supporting the idea that pharmacokientic models may need to be designed for specific populations of interest.  Creating similar pharmacokinetic models for use in a specific population may have two goals:  to adjust dosing criteria to be specific for a population, and/or to explore how additional variables (for example, concomitant medications) not included in the previous studies effect particular parts of the pharmacokinetics of apixaban.  

This study seeks to demonstrate how investigators can fit similar models to their pharmacokinetic data with the aim of accomplishing the goals of accurate modelling of pharmacokientics and exploration of effects of new varibales.  We use apixaban as a specific example, but our methodology can be generalized to other drugs where pharmacokientics are of interest.  Additioanlly, we focus only on pharmacokientics since blood plasma levels correlated closely with the pharmacodynamic effect of apixaban [-@byon2019apixaban]. Our approach leverages a Bayesian methodology to building pharmacokinetic models so that we may incorporate prior information from previous studies. Additionally, we describe how investigators can use *all* relevant data available to them to fit these models and make inferences, even if that data come from controlled studies.  Finally, we show how sparsity inducing priors can be applied to new variables in order to explore how those variables may effect apixaban pharmacokinetics, encouraging small effects but allowing for large effects to be detected. We present a small simulation study to demonstrate how smallest meaningufl effects can be detected through these priors as a function of sample size. Finally, we use an open source Bayesian language to develop our models, making our code freely available.  Previous models are constructed in a proprietary software toolset, which can come at a high cost. Creation of these models in a free tool removes a barrier to research, making these methods more widely available.



# Background

## Apixaban

Our study uses clinical and experimental plasma concentrations from patients who were prescribed apixaban. Apixaban is a direct acting oral anti-coagulant often prescribed for prevention of stroke and systemic embolism in patients with atrial fibrillation (AF) [-@BMSmonograph; -@byon2019apixaban].  Studies as recent as 2019 have reported excess variability in observed apixaban plasma concentrations in patients with AF [-@sukumar2019apixaban]. Since apixaban plasma concentrations correlate closely with anti-coagulation[-@upreti2013effect,-@frost2013safety,-@frost2013apixaban], excess variability in these concentrations may mean increased risk of bleeding. These findings have raised questions towards the optimal dosing of apixaban in older adults with AF encountered outside of clinical trials.

Additional research into determining factors which explain this excess variability beyond known clinical factors [-@gulilat2020drug] has consequently begun.

## Methods


## Bayesian Model

Our model specifies a population level effect of covariates (age, sex, weight (kg), serum creatinine $\mu \mbox{mol}$) on patient clearance, time to max concentration, and the ratio between absorption and elimination rates (a unitless parameter we refer to as $\alpha$). These effects are shared between the two populations, allowing information from one dataset to partially inform model fit on the other.  We also include a population level effect of concomitant amidarone on bioavailability of apixaban.  

We fit our model using Stan [-@gelman2015stan], an open source probabilistic programming language with interfaces to Python, R, Stata, Matlab, and more.  Fittting two datasets jointly is formally equivalent to fitting one dataset first and passing the posterior as a prior for a model for the other dataset.  However, such an approach requires summarization of the posterior, which may result in loss of information (such as covariance between draws, unless explicitly modeled).  The recommended approach is then to fit datasets jointly, as done in [-@fallingBetancourt].

### Dense Sampling (Dataset 1) Model

Since patients are observed multiple times in these data, this offers the opportunity to estimate random effects for Clearence $Cl$, time to mac concentration $t_{\max}$, ratio between elimination and absorption rates $\alpha = k_e/k_a$.

Let $X$ be a matrix of mean centered and standardized covariates for dataset 1.  For patient $j$, we model the pharmacokientic parameters as

$$ \log(Cl_{j}) = \mu_{Cl} + X\beta_{Cl} + z_{Cl, j} \sigma_{Cl}  $$
$$ \log(t_{\max,j}) = \mu_{t_{\max}} + X\beta_{t_{max}} + z_{t_{\max, j}}\sigma_{t_{\max}}  $$

$$ \operatorname{logit}(\alpha_{j})  =  \mu_{\alpha} + X\beta_{\alpha} + z_{\alpha, j}\sigma_{\alpha}  $$

Here, the $\mu$ are the population level means for the indicated pharmacokinetic parameters, the $\beta$ are the regression coefficients, the $z$ are standard normal random variables to account for random effects, and the $\sigma$ are the standard deviations of the population distribution for the indicated pharmacokinetic parameters. Additionally, we model the population mean for the bioavailability as $F = 1/(1 + e^{\mu_F}$, with a prior on $\mu_F$.  Both the $\mu$ and the $\beta$ are shared between datasets.

For dataset 1, we also model a delay between ingestion and absorption of apixaban.  The delay is modeled as 

$$ \delta_j = 0.5 \times b  $$

Where $b$ is a beta distributed random variable with parameters learned from the data.  The factor of 0.5 is used to ensure that at $t=0.5$ hours after ingestion, the predicted to be non-zero.

We use a one compartment pharmacokinetic model with first order elimination as our conditional mean

$$  C_{j}(t)= \begin{cases}\frac{F \cdot D}{C l_j} \frac{k_{e, j} \cdot k_{a, j}}{k_{e, j}-k_{a, j}}\left(e^{-k_{a, j}(t-\delta_j)}-e^{-k_{e, j}(t-\delta_j)}\right) & \delta_j \leq t \\ 0 & \text { else }\end{cases} \>. $$
Here, all parameters are estimated from data, and we have used the facts that

$$ t_{\max }=\frac{\ln \left(k_{a}\right)-\ln \left(k_{e}\right)}{k_{a}-k_{e}} $$
$$ \alpha = \dfrac{k_e}{k_a} $$

in order to solve for $k_e$ and $k_a$ for use in our PK model.  Finally, we specify a lognormal likelihood for dataset 1

$$ y_j \sim \mbox{Lognormal}(C_j(t), \sigma_1) \>. $$

For information of prior distributions, see our supplement.

### Real Life Data (Dataset 2) Model

Much of the structure from the previous model is translated to dataset 2.  However, there are a few differences.

Because patients in this dataset are not measured multiple times we do not estimate random effects or a time delay.  Hence, we model

$$ \log(Cl) = \mu_{Cl} + X\beta_{Cl} $$

$$ \log(t_{\max}) = \mu_{t_{\max}} + X\beta_{t_{\max}} $$

$$\operatorname{logit}(a) = \mu_\alpha + X\beta_{\alpha} $$

Where the $mu$ and the $\beta$ are shared between datasets.  Additionally, we model the bioavailbility as 

$$ \operatorname{logit}(F) = \mu_F   + \beta_{amio} \mbox{amiodarone}$$

as dataset 2 has information regarding concomitant amiodarone.  The prior for the effect of concomitant amiodarone is a sparsity inducing prior, meaning it encourages negligble effects (near 0) but will allow for large effects to be identified.

Finally, data from dataset 2 comes from patients who have been taking apixaban twice daily.  Hence, their initial plasma concentration on ingestion is not 0, but can be modeled using the pharmacokientics none the less.  Assuming the patients have been taking apixaban twice a day, 12 hours apart, for the last 5 days, the initial concentration can be shown to be

$$ C_0 = \sum_{j=1}^{10} C(12j) \>. $$

Here, $C(t)$ is the pharmacokintic profile with estimated coefficients for that patient.  See our supplement for a proof of this proposition.

Our pharmacokientic profile is again provided by a one compartment first order elimination 

$$  C(t)= c_0 + \frac{F \cdot D}{C l} \frac{k_{e} \cdot k_{a}}{k_{e}-k_{a}}\left(e^{-k_{a}(t)}-e^{-k_{e}(t)}\right)  $$
and we assume a lognormal likelihood

$$ y_j \sim \mbox{Lognormal}(C(t), \sigma_2) \>. $$
Note the likelihood for dataset 2 has a different observational noise component ($\sigma_2$) as compared to dataset 1 ($\sigma_1$).  This is because random effects can not be estimated from dataset 2, hence the residual variance is part observational noise and part between subject variability conditional on the subject covariates.

# Results

```{r load-in-data}
con = dbConnect(duckdb(),'data/database/apixaban_data.duckdb')

ute_data = tbl(con, 'ute_cleaned_data') %>% 
           collect() %>% 
           mutate(
             dataset = "Ute's Data",
             i = seq_along(subjectids)
           ) 

rommel_data = tbl(con, 'rommel_cleaned_data') %>% 
              collect() %>% 
              mutate(
                subjectids = as.character(subjectids),
                dataset = "Rommel's Data"
                )

dbDisconnect(con, shutdown=T)


```

```{r load-in-model}
fit = readRDS('model_008.RDS')

conc = function(time, d, f,cl, ke, ka, c0){
  d*f*ke*ka/(cl*(ke-ka)) * (exp(-ka*time) - exp(-ke*time)) + c0
}

```


```{r plot-model-predictions}

# Check for data from one of those data.
# Public apixaban data?
rommel_fit = fit %>% 
  spread_draws(r_C[i]) %>% 
  mutate(r_C = 1000*r_C) %>% 
  mean_qi() %>% 
  bind_cols(rommel_data) %>% 
  rename(predictions=r_C)


ute_fit = fit %>% 
  spread_draws(u_C[i]) %>% 
  mutate(u_C = 1000*u_C) %>% 
  mean_qi() %>% 
  bind_cols(ute_data) %>% 
  rename(predictions=u_C)

rommel_fit %>% 
  bind_rows(ute_fit) %>% 
  ggplot(aes(log(yobs_ng_ml), log(predictions), ymin = log(.lower), ymax = log(.upper)))+
  geom_pointrange(size=0.1)+
  geom_abline(color='dark grey')+
  facet_wrap(~dataset, scale='free')+
  theme(aspect.ratio = 0.62)+
  labs(x='Log Concentration', y='Log Prediction')

ggsave('prediction_v_actual.png', path='figures')
knitr::plot_crop('figures/prediction_v_actual.png')

```

```{r}

fit %>% 
  spread_draws(mu_cl, s_cl, mu_tmax, s_t, mu_alpha, s_alpha, mu_F, b_F_amio) %>% 
  mutate(
    cl = exp(mu_cl),
    tmax = exp(mu_tmax),
    a = plogis(mu_alpha),
    ka = log(a)/(tmax*(a-1)),
    ke = ka*a
  ) %>% 
  select(cl, tmax, ka, ke, mu_F, b_F_amio) %>%  
  crossing(amio = seq(0, 1, 0.05)) %>% 
  mutate(f = plogis(mu_F + b_F_amio*amio),
         y = conc(tmax, 5, f, cl, ke, ka, 0)) %>% 
  ggplot(aes(amio, y))+
  stat_lineribbon(.width = c(0.5, 0.8, 0.95, 0.99), size=0)+
  scale_fill_brewer(palette ='YlGnBu')+
  scale_x_continuous(labels = function(x) 400*x)

```

# References