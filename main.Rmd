---
title: "Pooling Pharmacokientic Information Using Heirarchical Models"
author:
  - "A. Demetri Pananos"
  - "Daniel J. Lizotte"
  - "Simon J. Bonner"
output: 
  pdf_document:
    includes:
      in_header: "preamble.tex"
date: "`r format(Sys.time(), '%B %d, %Y')`"
bibliography: references.bib
csl: academic-medicine.csl
---


```{r global-options, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(
  echo = F,
  message = F,
  warning = F,
  fig.height = 4,
  fig.align = 'center',
  dpi = 400,
  cache = F
)
```

```{r libraries}
library(tidyverse)
library(rstanarm)
library(tidybayes)
library(cmdstanr)
library(duckdb)
library(DBI)
library(table1)
source('R/utils.R')

options(readr.show_progress=F,
        readr.num_columns = 0)

theme_set(theme_light())
cmdstanr::register_knitr_engine(override = F)
```


# Introduction

One goal of personalized medicine is optimized dosing of drugs for individuals [-@morse2015personalized].  When considering optimal doses, a thorough understanding pharmacokinetic (what the body does to the drug) and/or pharmacodynamic (what the drug does to the body) effects are crucial.  To this end, models describing the mediation of pharmacokinetic/pharmacodynamic effects via clinical, genetic, and lifestyle factors have an important role in deciding which patients should get what dose. Models of this nature are sometimes published by research teams collaborating with drug manufacturers using data from clinical trials.

Independent investigators can find themselves in a situation in which data collection from a particular population of interest is achievable. If the data come from practice (e.g. a personalized medical clinic), there may be questions about how new variables not previously studied in clinical trials affect the pharmacokientics/pharamcodynamics of a particular drug.  Running large studies in order to examine the effects of these new variables, or discover effects of other variables, may be unrealistic due to a variety of constraints.  Consequently, investigators must think about how best to model the pharmacokinetics, for use in decision making *and* exploration, using the data available to them.

The oral anti-coagulant apixaban provides an illustrative example.  Pharmacokinetic models have been previously published [-@cirincione2018population;-@ueshima2018population] in collaboration with the drug's manufacturer using data from clinical trials.  These studies identified age, sex, body weight, renal function,  patient race, and CYP3A4 inhibitors as modulators of apixaban pharmacokinetics [-@cirincione2018population], though according to authors the effects of some of these variables were not large enough to require clinical dose adjustment. However, even after adjusting for the aforementioned factors, concentrations of apixaban in real life applications have been observed to be larger than what was reported in clinical trials [-@sukumar2019apixaban], raising questions as to the optimal dosing of apixaban for patients in different settings. Additionally, recent research has indicated appropriateness of dose adjustment criteria are unclear [-@vu2021critical], citing there is no reduction in safety associated with an increased exposure to apixaban in patients above 75 years of age, below 60kg of body weight, and EGFR lower than 50 mL/min. The uncertainty regarding dosing criteria and additional variability in concentrations in day to day use suggests that, while previously published models may be internally valid, these models may not be representative of all populations in which apixaban is to be applied.  That is to say, the models may lack a degree of external validity, thus supporting the idea that pharmacokinetic models may need to be tailored for specific populations of interest. When viewed through a Bayesian lens, the previous modeling work can act as an informative prior on various pharmacokinetic/pharmacodynamic measures.  Creating new models for populations of interest is then more of a "fine tuning" than an all together new approach.  Pharmacokinetic models for use in a specific population may then have two goals:  to adjust doses for a specific population, and/or to explore how additional variables (for example, concomitant medications) not included in the previous studies affect particular parts of the pharmacokinetics of apixaban.  

This study seeks to demonstrate how investigators can fit similar models to their pharmacokinetic data with the aim of accomplishing the goals of accurate modeling of pharmacokientics and exploration of effects of new variables.  We use apixaban as a specific example, but our methodology can be generalized to other drugs for which pharmacokientics are of interest.  Importantly, we only focus on pharmacokientics since blood plasma levels correlate closely with the pharmacodynamic effect of apixaban [-@byon2019apixaban;-@upreti2013effect;-@frost2013safety;-@frost2013apixaban]. Our approach leverages a Bayesian methodology to building pharmacokinetic models so that we may incorporate prior information from previous studies. Additionally, we describe how investigators can use *all* relevant data available to them to fit these models and make inferences, even if the data are not from controlled studies.  Also, we show how sparsity inducing priors can be applied to new variables in order to explore how those variables may effect apixaban pharmacokinetics, encouraging negligible effect sizes but allowing for large effects to be detected at the cost of a small amount of bias. We present a small simulation study to demonstrate how smallest meaningful effects can be detected through these priors as a function of sample size. Finally, we use an open source Bayesian language to develop our models, making our code freely available.  Previous models are constructed in a proprietary software tool set, which can present a barrier for some. Creation of these models in a free tool removes a barrier to research, making these methods more widely available.



# Background

## Apixaban

Apixaban is a direct acting oral anti-coagulant often prescribed for prevention of stroke and systemic embolism in patients with atrial fibrillation (AF) [-@BMSmonograph; -@byon2019apixaban].  Studies as recent as 2019 have reported excess variability in observed apixaban plasma concentrations in patients with AF [-@sukumar2019apixaban]. Since apixaban plasma concentrations correlate closely with anti-coagulation, excess variability in these concentrations may mean increased risk of bleeding. These findings have raised questions towards the optimal dosing of apixaban in older adults with AF encountered outside of clinical trials. Additional research into determining factors which explain this excess variability beyond known clinical factors [-@gulilat2020drug] has consequently begun.

## Variable Selection

Existing studies into pharmacokinetic modelling often use variable selection methods (e.g. variants of stepwise selection, including fitting all submodels [-@cirincione2018population;-@ueshima2018population]) when faced with the determining which variables effect the pharmacokientics. Many studies have noted that these techniques result in bias away from the null [-@whittingham2006we], exaggerated precision [-@altman1989bootstrap], inaccurate or uninterpretable $p-$values due to inability to properly incorporate uncertainty in the selection process [-@harrell2015regression], and can fail to select the "true" model with high confidence even when modeling assumptions are consistent with the true data generating process [-@smith2018step].  Hence, even in the best case scenario where the selection procedure identifies the correct variables, the resulting estimates may not be reliable.  Results from these studies methods make a convincing argument to avoid selection methods all together.

Variable selection methods are intended to answer the question "which variables are important in modeling the outcome", and although studies have demonstrated deficiencies with variable selection, they often do not provide an alternative answer.  From a Bayesian perspective, selection to include a variable in or out of a model defines a sort of prior on the parameter value; there is a strong preference for a null effect estimate unless the data provide sufficient evidence for free estimation of that effect.  Efforts to operationalize this prior structure in terms of Bayesian inference have lead to a wide variety of sparsity inducing priors, which include spike and slab priors[-@mitchell1988bayesian], and horseshoe[-@carvalho2010horseshoe] and Finnish horseshoe priors [-@piironen2017sparsity]. These approaches admit that while unlikely that the effects of unimportant variables are exactly 0, they may be small enough to be negligible.  These priors place the majority of their probability mass near 0, encouraging small effects to be estimated as something negligibly small, but allow for large effects to be identified at the cost of a small amount of bias.

Bias towards a null effect  can be acceptable when the goal is exploration and prediction.  The bias can act as a regularization for predictions hence combating overfitting, and can hedge estimates of novel effects when they are exaggerated due to high variance. To this end, we present a simulation study in which we use a sparsity inducing prior to estimate the effect of a concomitant medication on apixaban pharmacokinetics.  In particular, the medication is assumed to inhibit a particular gene important in the elimination of apixaban, making the bioavailability larger.  We place a double exponential (or Laplace) prior on the effect of the concomitant medication, as well as a prior on the parameter for the Laplace distribution.  This is similar to putting a LASSO penalty on the effect as well as a prior on the LASSO penalty strength [-@tibshirani1996regression].  Although our simulation only has a single variable of interest, many variables can be used with this prior structure.

For our simulation, we generate data from the posterior of a previously fit model [*CITE SECOND PAPER*]. We simulate 10 datasets from a pre-specified number of repeatedly sampled patients (we examine 5, 10, 20, 30, 40, and 50 repeatedly sampled patients) haven taken their first dose of the drug with a pre-specified and fixed effect of a concomitant medication on the bio-availability of the drug.  We assume that investigators can sparsely sample patients more easily, and so we simulate 10 times more sparsely sampled patients who have already achieved steady state. We do this so as to more closely resemble real life scenarios in which patients come into a clinic for a plasma measurement having already been on the drug for sometime. We examine effects of 0, 0.125, 0.25, 0.5, 1.0, and 1.5 on the logit scale (we use the logit scale since bioavailability is constrained to be between 0 and 1). 

## Why Is a Hierarchical Model Needed?

In this paper, we propose a pooling of both sparsely and repeatedly sampled data in a single model. Pooling information is not a new approach, and reasonable arguments could be made to use simpler models.  After all, if the sparsely sampled data models a continuous outcome as a function of covariates, why would investigators use a complex model when something simple like linear regression (or linear regression on log concentrations) may be sufficient?  While simpler approaches and criticisms of using unnecessarily complex models are valid, both linear modeling and mixed effects models for pooling suffer from important drawbacks in the case when attempting to combine sparsely sampled and repeatedly sampled data from different studies.  We examine those drawbacks below.

Linear regression can be, and has been[-@gulilat2020drug; -@vakkalagadda2016effect], used to model apixaban concentrations as a function of time and other covariates using sparsely sampled data.  When certain criteria are met, there is good reason to do so.  The concentration profile, $C(t)$, from a first order absorption with linear elimination pharmacokinetic model looks like

$$ C(t) = \frac{F \cdot D}{C l} \frac{k_{e} \cdot k_{a}}{k_{e}-k_{a}}\left(e^{-k_{a}t}-e^{-k_{e}t}\right) $$
Here, it is usually assumed that $k_e<k_a$ in order for the model to be identified[-@wakefield1996bayesian; -@salway2008gamma]. The elimination phase occurs when $t$ is sufficiently large, resulting in $C(t)$ being approximately exponential and $\log(C(t))$ being linear in time on the log scale with slope $-k_e$.  The assumption that measurement error is additive on the log scale facilitates use of linear regression.

This approach is common in pharmacokinetics when estimating the elimination rate but suffers from three important drawbacks generally. First, the elimination rate is not allowed to vary as a function of known factors which effect elimination rate, such as kidney function.  This can be ameliorated by specifying an interaction between time and those covariates known to effect elimination rate (though this has not been done in all studies[-@gulilat2020drug]).  Second, an exponential approximation is only appropriate when time is sufficiently large.  Clearly, the exponential approximation breaks down near $t=t_{max} = \log(k_a/k_e)/(k_a-k_e)$ and is completely inappropriate in the absorption phase when $t<t_{\max}$.  This affects estimates of max concentration in an appreciable way, resulting in an upward bias of $C_{\max}$ (the bias is proportional to $-k_a t_{\max}$ on the log scale).  Additionally, because $t_{\max}$ is not modeled per individual, estimates of $C_{\max}$ must rely on a point estimate of $t_{\max}$.  This results in uncertainty estimates of $C_{\max}$ which may be too narrow for a given individual.  Finally, the effects of covariates on other aspects of the pharmacokinetcs are undetermined. Assuming a linear model is used to model concentrations on the log scale, we find

$$ \log(C(t)) \approx \log(D) + \log(F) - \log(Cl) + \log(k_e) + \log(k_a) - \log(k_e-k_a) - k_at - k_et = \log(D) + \beta_0 + \beta_1t \>. $$
Here, $\beta_0 =  \log(F) - \log(Cl) + \log(k_e) + \log(k_a) - \log(k_e-k_a)$.  If covariates are included in the model, then although changes in log concentration may be accurate (in so far as the sign of the chance in log concentration is concerned), *where that change occurs is under determined*.  Did concentration increase because bioavailability ($F$ in the log linear model) increased, or was it because the clearance rate ($Cl$ in the log linear model) decreased?  We can't say for certain from this model. In order to determine if a change in concentration was due to an increase/decrease in a pharmacokinetic parameter, each pharamacokinetic parameter must be modeled as functions of covariates. How salient these drawbacks are is up to the investigator, but if any of them are important to decision making for personalized medicine then a linear model will not be appropriate.

Mixed effects models can be used to pool information from many datasets.  Meta-analysis is perhaps the most prevalent example of this approach.  A typical example may be pooling data from studies conducted using similar protocols across multiple centers.  Ideally, the data are collected under similar protocols, making assumptions regarding the likelihood and exchangeability of appropriate units tenable.  In the scenario we describe, where information from at least two studies with different protocols are to be pooled, we believe a mixed effect model specifying between study variation is *not* appropriate due to subjects not being exchangeable between studies.  Recall, a sequence of random variables $\theta_1, \dots, \theta_n$ is said to be exchangeable in their joint density $p(\theta_1, \dots, \theta_n)$ is invariant permutations of the indicies $(1, \dots, n)$[-@gelman1995bayesian].  If no other information, other than observed data, is available to distinguish any of the $\theta_j$ from any others, and no ordering or grouping of parameters can be made, one must assume exchageability of the $\theta$.  In the scenarios we describe, we do have additional information which can be used to distinguish the $\theta$.  In particular, sparsely sampled data will have a larger estimated residual error than repeatedly sampled data.  This is because the residual variance is a combination of within and between subject variation. There are then 2 residual variances to be estimated: one for the repeatedly sampled data and one for the sparsely sampled data.  When pooling sparsely sampled and repeatedly sampled data together, individuals within subjects are exchangeable because of the common residual variance within study. However, subjects are not exchangeable between studies because permutations of the subject indicies fail to account for which subject should be associated with which residual error.


# Methods

By now, we have established a few points which are worth reiterating:

* For cases which populations of interest display sufficient differences as compared to data presented in clinical trials, the tailoring of a pharmacokinetic model to the intended population for use in personalized medicine applications may be desirable.  Apixaban is one such drug, and we use data from apixaban in our case study.


* Models developed for specific populations may serve two purposes: prediction and exploration of novel effects.  Previous studies rely on variable selection procedures to identify novel predictors of pharmacokinetics.  As of late, many simulation studies have demonstrated deficiencies in variable selection procedures.  We propose the use of sparsity inducing priors to regularize negligible effects towards 0 while keeping those variables in the models.

* Investigators may want to make use of all pharmacokinetic data available to them, be they sparsely sampled and of an observational nature, or repeatedly sampled from well controlled clinical studies.  Typical methods for pooling this information (e.g. mixed effect models, or simply concatenating datasets) are not universally appropriate in cases when data come from studies with vastly different protocols due to possible violations of exchangeability of subjects between studies.

In what follows, we present a Bayesian model which addresses all three points above.  We present a model of apixaban pharmacokinetics which combines data from two studies with different protocols.  We demonstrate how sparse priors can be used to estimate the effect of a potentially novel predictor, and present a simulation study to investigate how relative sample sizes between the two studies and effect size of the predictor effect estimation.

## Bayesian Model

Our model specifies a population level effect of covariates (age, sex, weight (kg), serum creatinine ($\mu \mbox{mol}$)) on patient clearance, time to max concentration, and the ratio between absorption and elimination rates (a unitless parameter we refer to as $\alpha$). These effects are shared between all populations, allowing information from one dataset to partially inform model fit on the other.  We also include a population level effect of concomitant amidarone on bioavailability of apixaban.  We fit our model using Stan [-@gelman2015stan], an open source probabilistic programming language with interfaces to Python, R, Stata, Matlab, and more.

Let $s = 1 \dots K$ denote the number of studies being pooled together.  Each study has $j = 1 \dots N_s$ subjects, whom are observed at times $t_i$ for $i = 1 \dots T_j$.  For sparsely sampled data, $T_j=1$, meaning we have only one sample per subject.  For repeatedly sampled data, $1<T_j$, meaning we have multiple measurements from the same subject.  In our data, we use $K=2$ studies.  There are $N_1=36$ subjects in our repeatedly sampled data, and $N_2=402$ subjects in our sparsely sampled data.  The repeatedly sampled subjects are each sampled $T=8$ times.

Our model assumes there are population level effects of each covariate on the pharmacokientic parameters, and that the distribution of pharmacokinetic parameters given covariates $\mathbf{x}_{j, s}$ from subject $j$ in study $s$ are the same between studies.  Let $\theta_{j, s}$ be a vector of pharmacokinetic parameters for subject $j$ in study $s$.  In our model, $\theta_{j, s}$ is comprised of subject clearance rate, time to max concentration, ratio between elimination and absorption rates, and bioavaiability respectively  $\theta_{j,s} = (Cl_{j, s}, t_{\max, j, s}, \alpha_{j, s}, F_{j, s})$.  Our model is depicted as a Bayes net in Figure 1.

We estimate two non-pharmacokientic parameters from our data as well.  Let $\delta_{j, s}$ be the time delay between ingestion of the bolus dose and absorption into the blood stream, and let $c_{0, j, s}$ be the initial concentration of apixaban in the blood stream at the time of ingestion.  The time delay $\delta$ can not be estimated from the sparsely sampled data because only a single measurement was taken, but can be estimated from the repeatedly sampled data.  Therefore we assume $\delta_{j, 2}=0 \quad \forall j$.  Additionally, sparsely sampled patients are assumed to be in steady state and therefore have a non-zero initial concentration of apixaban in their blood at the time of ingestion, as compared to repeatedly sampled patients which had not taken apixaban prior to the study.  Therefore, $c_{0, j, 1} = 0 \quad \forall j$.  The quantity $c_{0, j , 2}$ can be estimated from the other pharmacokinetic parameters assuming subjects have been taking apixaban twice daily with perfect adherence for the last 5 days.  We provide a proof of this proposition in the appendix by solving the associated differential equation with forcing functions for each dose using the Laplace Transform.

Each pharmacokinetic parameter has an associated set of regression coefficients and intercept term.  Each pharmacokinetic parameter is regressed on subject covariates $\mathbf{x}_{j, s}$ in the following way:

$$ \log(Cl_{j, s}) = \mu_{Cl} + \mathbf{x}_{j, s}^{Cl} \beta_{Cl} $$
$$ \log(t_{\max,j, s}) = \mu_{t} + \mathbf{x}_{j, s}^{t} \beta_{t} $$
$$ \operatorname{logit}(\alpha_{j, s}) = \mu_{\alpha} + \mathbf{x}_{j, s}^\alpha \beta_{\alpha} $$
$$ \operatorname{logit}(F_{j, s}) = \mu_{F} + \mathbf{x}_{j, s}^{F} \beta_{F} $$

Here, we have added superscripts to the $\mathbf{x}$ to indicate that different covariates may be used in each regression. The $\beta$ are regression coefficients and $\mu$ are intercepts for the parameter indicated in the subscript. We include random effects for repeatedly sampled subjects. Each $\theta_{j, s}$ is used to predict the concentration profile $C(t)$.  We use a one compartment pharmacokinetic model with linear elimination as our $C(t)$, namely

$$ C_{j, s}(t_i) =  \begin{cases} c_{0, j, s} + \dfrac{D_{j, s} F_{j, s} k_{e, j, s} k_{a, j, s}}{Cl_{j, s}(k_{e, j, s} - k_{a, j, s})} \Bigg( e^{-k_{a, j, s}(t_i - \delta_{j, s})} - e^{-k_{e, j, s}(t_i - \delta_{j, s})} \Bigg)  & \delta_{j, s} \leq t_i \\ 0 & \mbox{else} \end{cases}$$

Again, if $s=1$ (indicating repeated sampling) then $c_{0, j, 1} = 0 \quad \forall j$ since patients from this study take apixaban for the first time.  If $s=2$ (indicating sparse sampling) then $\delta_{j, 2}$ is assumed to be 0 $\forall j$ since the delay can not be estimated from a single observation.  Finally, the predicted latent concentrations are used in the likelihood.  We use a lognormal likelihood for both datasets, with variance differing by study

$$ y_{i,j,s} \sim \operatorname{Lognormal}\Big( \log(C_{j, s}(t_i)), \sigma_s \Big)  \>.$$


\begin{figure}[t!]
	
\centering
\begin{tikzpicture}
	
\node[latent](b){$\beta$};
\node[latent, right=of b](mu){$\mu$};

\node[latent, below = of b](theta){$\theta$};
\node[obs, left = of theta](x){$\mathbf{x}$};


\node[latent, below = of theta](C){$C(t)$};
\node[obs, left = of C](t){$t$};
\node[obs, below = of C](y){$y$};
\node[latent, left = of y, xshift=-2cm](s){$\sigma$};

\edge{b}{theta};
\edge{mu}{theta};
\edge{x}{theta};
\edge{theta}{C};
\edge{t}{C};
\edge{C}{y};
\edge{s}{y};

\plate[]{t_y_pairs}{(t)(y)(C)}{$i=1 \dots T_j$};
\plate[]{subjects}{(t_y_pairs)(x)(theta)}{$j=1 \dots N_s$};
\plate[]{study}{(subjects)(s)}{$s=1 \dots K$};
\end{tikzpicture}
\caption{Bayes net for our hierarchical apixaban pharmacokientics model.  Here, $\beta$ and $\mu$ are regression coefficients and intercepts for the effects of covariates on pharmacokientic parameters.  The effects are assumed to apply to all studies, meaning that the effect of age on time to max concentration (as an example) is the same for all studies.  If protocols are different between studies, then each study may have a different residual variance term $\sigma_s$.  This differing residual variance is what prevents subjects from being considered exchangeable between studies.  When permiting the joint distirbution of $\theta_{j, s}$, one needs to keep track of which $\theta$ requires which $\sigma$, thus preventing the subjects from being considered exchangeable.}
\end{figure}


# Results

```{r load-in-data}
con = dbConnect(duckdb(),'data/database/apixaban_data.duckdb')

ute_data = tbl(con, 'ute_cleaned_data') %>% 
           collect() %>% 
           mutate(
             dataset = "Sparsely Sampled Data",
             i = seq_along(subjectids)
           ) 

rommel_data = tbl(con, 'rommel_cleaned_data') %>% 
              collect() %>% 
              mutate(
                subjectids = as.character(subjectids),
                dataset = "Repeatedly Sampled Data"
                )

dbDisconnect(con, shutdown=T)

d = bind_rows(rommel_data, ute_data) %>% 
    distinct(subjectids, .keep_all=T) %>% 
    replace_na(list(amiodarone_mg_day=0)) %>% 
    rename(Age = age,
           `Weight (kg)` = weight_kg,
           `Creatinine (micromol/L)` = creatinine_micromol_l,
           Sex = sex, 
           `Concomitant Amiodrone (mg/day)` = amiodarone_mg_day)
```


```{r table-1, caption='Descriptive statistics for repeatedly sampled and sparsely sampled data.  Note, amiodarone is a CYP3A4 inhibitor.  The study which generated repeatedly sampled data excluded any patients whom were taking CYP3A4 inhibitors, so all patients in the repeatedly sampled data are assigned a value of 0 for concomitant amiodarone.'}

table1::table1(~Age + `Weight (kg)` + `Creatinine (micromol/L)` + Sex + `Concomitant Amiodrone (mg/day)`| dataset, data = d) %>% 
  t1kable(booktabs=T)


```

The results from our simulation study are shown in figure \ref{fig:simulation-results}. The precision of the estimate of effect of concomitant drug use increases as the number of repeatedly sampled (and sparsely sampled) patients increases.  Shown in red are the sample means of the 10 runs (black dots).  On average we see a small amount of bias in the estimates.  This is expected since the sparsity inducing priors have the majority of their density in a small neighborhood of 0, regularizing effects towards 0.  For purposes of discovery, these biases may be acceptable if the result is a decrease in model variability.


When using real data, our model can accurately predict both repeatedly sampled and sparsely sampled data.  Shown in figure \ref{fig:plot-model-predictions} is a log-log plot of predicted and actual concentrations for both datasets.  The model makes more accurate predictions for repeatedly sampled patients (because it is able to estimate the random effect in each pharmacokinetic parameter).  The apparent increase in prediction error for the sparsely sampled can be explained by the absence of random effects for each patient.  The within and between patient variation manifests as measurement error solely, thus leading to lower predictive ability.

With a model for the pharmacokinetics of apixaban in hand, estimates of salient pharmacokinetic phenomena can be easily obtained.  In figure \ref{fig:max-concentration}, we use our model to estimate the max concentration for the reference patient under different doses of amiodarone.  Through our model, we estimate concomitant amiodarone increases bioavailability, which in turn increases max concentration.  Shown in black is the expected max concentration conditioned on concomitant amiodarone dose, as well as 95% equal tailed posterior credible intervals.

Additionally, we contrast the pooled model's estimates of covariate effects with estimates from model's fit to either the sparse or repeatedly sampled data. Marginal posterior densities for the effects of covariates on the pharmacokientic parameters are shown in figure \ref{fig:effect-estimates}.  In most cases, the effects seem to have higher precision due to the increase in sample size, and generally there is no large disagreement in either sign or magnitude of effect estimates.  


# Discussion

The Bayesian model we present pools information across studies which may differ in study protocol.  Doing so allows investigators to make use of all available data -- be they from controlled studies, or arising from day to day patient interactions in a personalized medicine clinic -- to fine tune pharmacokinetic models to populations of interest. However, this is just one possible model out of a family of similar models. One extension worth mentioning is estimating heterogeneity of effects between studies.  Our model assumes that for a given covariate, the effect is the same in different studies; the effect of weight on the clearance rate is the same across studies, for example.  This need not be assumed, and it may be the case that allowing for heterogeneity of effects between study populations may help explain additional variation beyond what measured covariates already explain.  The extension to include heterogeneity of effect is straight forward for our model.  In our Bayes net, we would add an additional plate enclosing the first three plates as well as $\beta$ and the $\mu$, and add nodes for population parameters leading into $\beta$ and $\mu$.  We choose not to implement this extension because our data consists of only two studies, making inference on the between study variability in effects difficult to estimate reliably.

To demonstrate how our model can be used to discover novel predictors of pharmacokientics, we included a simulation study in which we place a double exponential prior on a potentially novel covariate's effect on the bioavalability of the drug.  The double exponential prior acts as a sparsity inducing prior, pulling large effects towards 0 as the LASSO does. Our simulation study showed that our model is able to estimate the effect of this novel covariate reliably, even in circumstances where only a small amount of data on repeatedly sampled patients are available to investigators.  The estimates are biased towards the null due to the sparsity inducing prior. This bias attenuates with more data becoming available, and can also change depending on prior hyperparameters. From an estimation perspective, although the estimates of the effects are biased, they may be better suited to predict population effects due to this decrease in variability, similar to the phenomenon displayed by the James-Stein estimator.  We believe that since the goal of exploration is not to get the estimate right the first time, but to rather to discover new avenues for future research, therefore the exchange of variance for bias is not only acceptable but also preferable.

Finally, we applied our model in a case study of apixaban.  We pooled data from two sources; one from a well controlled clinical study, and the other from an observational setting.  We used a sparsity inducing prior to regularize estimates of the effect of concomitant amiodarone on bioavailability of apixaban.  Concomitant amiodarone's effect on apixaban concentration has been previously studied [-@gulilat2020drug], however that model is more descriptive whereas our model is mechanistic (in so far as we model the pharmacokientics explicitly) and incorporates prior information from previous studies.  The findings in our case study and previous work agree; concomitant amiodarone is associated with an increase in apixaban concentrations. It is difficult to evaluate if the magnitudes are similar however, mainly because our model posits a multiplicative effect whereas previous models assume an additive effect.  However, our model is capable of providing richer inferences due to the mechanistic approach and fully Bayesian analysis.  We can propagate uncertainty in the effect of concomitant amiodarone through to other salient pharmacokinetic measures, like max concentration (see figure y).  Additionally, uncertainty in other pharmacokinetic measures can be propagated. For example, where as previous models relied on a point estimate of time to max concentration -- which was the same for each subject -- our model can estimate each patient's time to max concentration (conditioned on covariates) and uncertainty in that estimate propagates through to max concentration.  The posterior distribution of max concentration then captures all uncertainty relevant to the decision, meaning credible intervals should -- at least in theory -- also have better coverage for individuals.  Though a similar Bayesian pharmacokinetic model could be fit using only the sparsely sampled data, pooling information using repeatedly sampled data should be beneficial because of the high precision in estimates of covariate effects afforded by the repeated sampling.

The marginal posterior distributions of the effects display behavior consistent with partially pooled models.  Models fit to each dataset could be considered as a non-pooled estimate, where as our model -- which combines information from multiple datasets -- can be considered as a pooled estimate.  Partially pooled models have the effect of regularizing estimates towards the population mean, but the size of this regularization depends on the precision and magnitude of the estimate. This behavior is most clearly shown in the radon example provided in chapter 12 of Gelman and Hill's book on multilevel modelling[-@gelman2006data]. Those counties with large effects and high precision see little regularization when comparing non-pooled estimates to pooled estimates.  Those counties with large effects and small precision see a strong amount of regularization (see figure 12.1 in  Gelman and Hill [-@gelman2006data]). Similar explanations can be applied to our model.  As an example, we see that the effect of weight on clearance ($Cl$ in our model) has been regularized to be a compromise of the estimates obtained from models fit on the repeatedly and sparsely sampled data separately.  Additionally, we can see that there is little regularization in effects where one dataset provides a high precision estimate (as in creatinine's effect on clearance). The tendency for partially pooled models to regularize towards the population mean has the effect of trading variance for bias, a theme that has permeated this work.  This should in principle result in estimates of the effects with smaller root mean squared error.

Our study is not without limitations.  Firstly, our repeatedly sampled data come from a study concerning patients with Non-Alcoholic Fatty Liver Disease (NAFLD).  Some patients in this study had NAFLD, others did not.  Our sparsely sampled data did not collect this variable, and so technically it should be considered missing.  One strategy is to impute this variable, be it though Frequentist methods or Bayesian methods.  We choose not to impute this and simply exclude it from our model since the study which generated the repeatedly sampled data failed to detect a statistically significant effect of NAFLD on apixaban pharmacokinetics [-@tirona2018apixaban]. Additionally, because patients in the sparsely sampled data were sampled only once, we were forced to assume their time delay was 0.  The time delay is most probably non-zero, and making this assumption may bias estimates of other pharmacokientic measures.  Finally, the subjects in each study are quite different with subjects in the repeatedly sampled data being younger, healthier, and with better kidney function on average. Since subjects in the sparsely sampled data are generally different, a linear effect of covariates on pharmacokientic parameters may not be appropriate due to extrapolation.  A possible remedy for this would be to model the effects of covariates using splines or other suitably flexible methods.  If additional subject matter expertise is available, investigators may choose to model the effects with monotone-splines.  We believe specifications about the functional form of effects are best done with the aid of subject matter experts (pharmacologists, physicians, etc) and opt for the simplest non-trivial functional form for our effects.

# Conclusion

In this study, we demonstrated how investigators could accomplish the goals of accurate modelling of pharmacokientics and exploration of new variables via the use of a heirarchical Bayesian model of pharmacokientics. The model pools information from multiple studies and shrinks estimates of effects.  The result is a trade off of variance for bias, which should improve predictive accuracy.  Additioanlly, we peformed a simulation stduy to demonstrate how sparisty inducing priors can be used to indentify effects of new variables.  We showed that, even in small samples, a small amount of bias is observed in estimates of novel effects and this bias attenuates with more data. Future research may include modelling heterogeneity of effect by adding another level to the heirarhcy.

\newpage
# Figures


```{r simulation-results, fig.cap = 'Results from our simulation study.  Black dots represent the estimated effect of a novel predictor.  Red dots indicate the average estimate across the 10 repititions. Data are faceted by the number of repeatedly sampled patients.  Smaller datasets show more bias towards the null.  This bias attenuates as sample size increases.' }
sim_results<-list.files('python/simulation_data/', full.names = T) %>% 
             map_dfr(read_csv) %>% 
             mutate(dense_label = str_c('N repeatedly sampled = ', num_dense_patients))


dense_patients = c(5, 10, 20, 30, 40, 50)
facet_labs = str_c('N repeatedly sampled = ', dense_patients)
names(facet_labs) = dense_patients


sim_results %>%
  rename(estimate=mean) %>%
  ggplot(aes(amio_effect, estimate))+
  geom_abline(color = 'dark grey')+
  geom_point(alpha = 0.5)+
  stat_summary(geom='point', color = 'red')+
  facet_wrap(~num_dense_patients, labeller = as_labeller(facet_labs))+
  labs(x='True Effect (Logit Scale)', y = 'Estimated Effect')


```




```{r load-in-model}
fit = readRDS('combined_data_model.RDS')

conc = function(time, d, f,cl, ke, ka, c0){
  d*f*ke*ka/(cl*(ke-ka)) * (exp(-ka*time) - exp(-ke*time)) + c0
}

```


```{r plot-model-predictions, fig.cap = 'Predicted vs observed concentrations for both datasets on the log scale. Note each plot has a seperate scale. Sparsely sampled data can not be predicted as accurately as the repeatedly sampled data, due in part to the inability to estimate patient random effects in pharmacokinetic parameters.  This additional variance left unexplained manifests as measurement error.'}

# Check for data from one of those data.
# Public apixaban data?
rommel_fit = fit %>% 
  spread_draws(r_C[i]) %>% 
  mutate(r_C = 1000*r_C) %>% 
  mean_qi() %>% 
  bind_cols(rommel_data) %>% 
  rename(predictions=r_C)


ute_fit = fit %>% 
  spread_draws(u_C[i]) %>% 
  mutate(u_C = 1000*u_C) %>% 
  mean_qi() %>% 
  bind_cols(ute_data) %>% 
  rename(predictions=u_C)

rommel_fit %>% 
  bind_rows(ute_fit) %>% 
  ggplot(aes(log(yobs_ng_ml), log(predictions), ymin = log(.lower), ymax = log(.upper)))+
  geom_pointrange(size=0.1)+
  geom_abline(color='dark grey')+
  facet_wrap(~dataset, scale='free')+
  theme(aspect.ratio = 0.62)+
  labs(x='Log Concentration', y='Log Prediction')

```

```{r max-concentration, fig.cap='Estimated max concentration as a function of concomitant amiodarone for a reference patient.  Concomitant amiodarone is estimated to increase apixaban bioavailability, thus leading to an increase in max concentration. The uncertainty in the effect of concomitant amiodarone is propogated through to the estimate of max concentration.  If max concentration is a key quqntity in deicion making, propogation of this uncertainty is crucial.'}

fit %>% 
  spread_draws(mu_cl, s_cl, mu_tmax, s_t, mu_alpha, s_alpha, mu_F, b_F_amio) %>% 
  mutate(
    cl = exp(mu_cl),
    tmax = exp(mu_tmax),
    a = plogis(mu_alpha),
    ka = log(a)/(tmax*(a-1)),
    ke = ka*a
  ) %>% 
  select(cl, tmax, ka, ke, mu_F, b_F_amio) %>%  
  crossing(amio = seq(0, 1, 0.05)) %>% 
  mutate(f = plogis(mu_F + b_F_amio*amio),
         y = conc(tmax, 5, f, cl, ke, ka, 0)) %>% 
  ggplot(aes(amio, y))+
  stat_lineribbon(.width = c(0.5, 0.8, 0.95), size=1)+
  scale_fill_brewer(palette ='YlGnBu')+
  scale_x_continuous(labels = function(x) str_c(400*x, ' mg'))+
  scale_y_continuous(labels = function(x) 1000*x)+
  labs(x='Concomitant Amiodarone',
       y = 'Apixaban concentration (ng/ml)',
       fill = 'Credible level')

```

```{r effect-estimates, fig.cap='Estimated covariate effects from models fit to each dataset seperately and the pooled model.', fig.height=6}
dense_fit = readRDS('dense_model.RDS')
sparse_fit = readRDS('sparse_model.RDS')

extract_coefs = function(fit, model){
  
  gather_draws(fit, `mu_.*`, `b_.*`, regex = T) %>% 
    mutate(model=model)
}

models = list(dense_fit, sparse_fit, fit)
model_names = c('Repeatedly Sampled','Sparsely Sampeld','Pooled')

b = map2_dfr(models, model_names, extract_coefs)

covar_pkvar_names = tribble(~pkp, ~pk_var,
                            'a', 'alpha',
                            't', 't[max]',
                            'F', 'F',
                            'cl', 'Cl')

b %>% 
  filter(grepl('b', .variable)) %>% 
  mutate(.variable = str_replace(.variable, 'is_male', 'sex')) %>% 
  separate(.variable, c('b','pkp','covar')) %>% 
  left_join(covar_pkvar_names) %>% 
  mutate(covar = str_to_title(covar)) %>% 
  ggplot(aes(.value, fill = model))+
  geom_density(alpha=0.5, position = 'identity', color = 'black')+
  facet_wrap(~pk_var+covar, scale = 'free', labeller = label_parsed)+
  labs(fill='', x = 'Estimate', y = '')+
  theme(legend.position = 'top')+
  scale_y_continuous(labels = c())

```

```{r, include=F}
d %>% 
  select(Age, `Weight (kg)`, `Creatinine (micromol/L)`, dataset) %>% 
  pivot_longer(cols=c('Age','Weight (kg)', 'Creatinine (micromol/L)')) %>% 
  ggplot(aes(value, fill=dataset))+
  # geom_histogram(aes(y = ..count../sum(..count..)), alpha = 0.5, position='identity')+
  geom_density(alpha = 0.5)+
  facet_wrap(~name, scales = 'free_x')
```


\newpage


# References